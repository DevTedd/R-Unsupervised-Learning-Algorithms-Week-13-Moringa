---
title: "Week 13 2nd"
author: "Ted"
output: html_document
---
# Part 2: Research Question

## This section of the assessment covers unsupervised learning with R. 

Kira Plastinina (Links to an external site.) is a Russian brand that is sold through a defunct chain of retail stores in Russia, Ukraine, Kazakhstan, Belarus, China, Philippines, and Armenia. The brand’s Sales and Marketing team would like to understand their customer’s behavior from data that they have collected over the past year. More specifically, they would like to learn the characteristics of customer groups.

1.Perform clustering stating insights drawn from your analysis and visualizations.

2. Upon implementation, provide comparisons between the approaches learned this week i.e. K-Means clustering vs Hierarchical clustering highlighting the strengths and limitations of each approach in the context of your analysis. 

*Your findings should help inform the team in formulating the marketing and sales strategies of the brand.*

### You will create a Markdown which will comprise the following sections. 

1. Problem Definition
2. Data Sourcing
3. Check the Data
4. Perform Data Cleaning
5. Perform Exploratory Data Analysis  (Univariate, Bivariate & Multivariate)
6. Implement the Solution
7. Challenge the Solution
8. Follow up Questions


```{r}
library(readr)
df <- read.csv("online_shoppers_intention.csv")
head(df)

```
### Data Description 

The dataset consists of 10 numerical and 8 categorical attributes.
The 'Revenue' attribute can be used as the class label.

"Administrative", "Administrative Duration", "Informational", "Informational Duration", "Product Related" and "Product Related Duration" represents the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real-time when a user takes an action, e.g. moving from one page to another. 

The "Bounce Rate", "Exit Rate" and "Page Value" features represent the metrics measured by "Google Analytics" for each page in the e-commerce site. 

The value of the "Bounce Rate" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave ("bounce") without triggering any other requests to the analytics server during that session. 

The value of the "Exit Rate" feature for a specific web page is calculated as for all pageviews to the page, the percentage that was the last in the session.

The "Page Value" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. 
The "Special Day" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with the transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. 

The dataset also includes the operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.

## 1. Problem Definition

Be able to identify the characteristics of customer groups

## 2. Data Sourcing 

Its from the collector themselves

## Data checking

```{r}
print(df)
print("The no of columns")
print(ncol(df))
print("The no of rows")
print(nrow(df))
```


## 4. Data Cleaning 
```{r}
# Checking for na values
print(colSums(is.na(df)))
#only 14 rows missing, we will omit them

df<- na.omit(df)
```


## Finding outliers

```{r}
boxplot(df$Administrative_Duration)
#Mostly outliers

boxplot(df$Informational_Duration)
# here too

boxplot(df$BounceRates)
#here too

```
Scaling the values will be required for graphs. Lets gets some insights to the data
```{r}
#Lets check where most visitoes come from

getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

country.mode <- getmode(df$Region)
country.mode

```
The most common region was 1
```{r}
#The most common visitor type?
visitor.mode <-getmode(df$VisitorType)
visitor.mode
```
Most visitors are returning 

```{r}
#Most active month
month.mode <- getmode(df$Month)
month.mode
```
The most active month was may


```{r}
#Most active week period
week.mode <- getmode(df$Weekend)
week.mode
```
Not the weekend

```{r}
head(df)
```

### Lets visualize more of this data

```{r}
rev <- df$Revenue
revs <- table(rev)
barplot(revs, xlab = "Revenue")
#The age distribution
```



```{r}
vis <- df$VisitorType
gues <- table(vis)
barplot(gues, xlab = "Visitor Types")
#The age distribution
```




```{r}

months <- table(df$Month)
barplot(months, xlab = "Ages")
#The age distribution
```
## Bivariate Analysis

```{r}
# find the covariance between a variety of the features
rev <- df$Revenue
bos <- df$BounceRates
dm <- df$Administrative_Duration
id <-df$Informational_Duration
prd <- df$ProductRelated_Duration

vis <- df$VisitorType
os <- df$OperatingSystems
spec <- df$SpecialDay
cov(rev,os)

```

```{r}
cov(rev,bos)
```

```{r}
cov(rev,spec)
```
```{r}
cov(rev,id)
```
The revenue and information duration are correlated
```{r}
cov(rev,prd)
```
The revenue and Product Related Duration +ve 

```{r}
cov(rev,dm)
```
The revenue and administrative duration +ve 



### only the ones with postive covariance
```{r}
cor(rev,id)
#a small postive correlation 

cov(rev,prd)
#a large positve correlation 

cov(rev,dm)
#an medium postive correlation
```

## checking correlation matrix
```{r}
num_ads <- unlist(lapply(df, is.numeric))
num_ad <- df[ , num_ads]

cor(num_ad)
```
# 6. Moving on to data cleaning for model preparation

```{r}
X <- df[, c(1, 2, 3, 4,5,6,7,8,9,10,12,13,14,15,17)]
y <- df[, "Revenue"]
library(superml)
label <- LabelEncoder$new()
```



### Label encoding the collumns
```{r}

X$Weekend <- as.integer(X$Weekend)
str(X)
```

### K-Means Clustering

```{r}
# Applying the K-means clustering algorithm with no. of centroids(k)=2
# ---

result<- kmeans(X,2) 
result$size
```
```{r}
result$cluster
# 
par(mfrow = c(2,2), mar = c(5,4,2,2))
#
plot(X[c(1,2)], col = result$cluster)
#
plot(X[c(3,4)], col = result$cluster)
```



```{r}
plot(X[c(1,2)], col = y)
```
```{r}
table(result$cluster, y)
```
#### This model did not do so well in classifying the clusters available into 2 groups 

## Trying out Hierarical Clusters

```{r}
#The first step is to scale the data
XS <- scale(X)
head(XS)
```
```{r}
d <- dist(XS, method = "euclidean")
# We then hierarchical clustering using the Ward's method
# ---
# 
res.hc <- hclust(d, method = "ward.D2" )

plot(res.hc, cex = 0.6, hang = -1)

```
```{r}
#Trying a differnt method
res.hc <- hclust(d, method = "average" )

plot(res.hc, cex = 0.6, hang = -1)

```

### That didnt go very well, changing it to
## DBSCAN

```{r}

library("dbscan")
db<-dbscan(X,eps=1,MinPts = 4)
print(db)
```

```{r}
hullplot(X,db$cluster)
```

```{r}

db<-dbscan(XS,eps=3,MinPts = 4)
print(db)
```
```{r}
hullplot(XS,db$cluster)
```

